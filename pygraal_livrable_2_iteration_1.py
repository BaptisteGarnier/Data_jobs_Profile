# -*- coding: utf-8 -*-
"""PyGraal_Livrable_2_ITERATION_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1doBNy8ywSlzrGvYFNBsLZGvAUpFTYhcR

Pour réaliser cette première itération, nous repartons du dataset auquel ont été apporté les modifications suivantes:

- Suppression des NaNs sur la variable cible ('Q5')

- Remplacement des NaNs par le mode pour chaque variable correspondant à des questions à choix unique

- Encodage des colonnes des questions à choix multiples par 0/1 selon NaN ou valeur

- Réduction du Dataset aux entrées des participants professionnels (ayant une profession précise, hors 'étudiant', 'sans emploi' et 'autre')
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
sns.set_theme()

df = pd.read_csv('/content/drive/MyDrive/PyGraal/df_pro.csv', index_col=0)

"""# Analyse de la variable cible

Comme vu précédemment, la valeur cible est 'Q5' (poste actuellement occupé) et après un premier traitement, elle contient 10 valeurs uniques.
"""

plt.figure (figsize=(10,10))
plt.pie(df['Q5'].value_counts(),
        autopct = lambda x: str(round(x, 2)) + '%',
        labels=df['Q5'].value_counts().index,
        pctdistance=0.7,
        shadow =True,
        colors = ['#dddddd', '#81d8d0','#ffff66', '#ff7f50',
                  '#a0db8e', '#c0d6e4', '#ffc0cb', '#ffa500', '#808080' , '#6897bb'])
plt.title("Distribution du panel de répondants par poste hors étudiant/autres/sans emploi",fontsize=15, fontweight='bold');

"""Le domaine de la Data est en constante évolution, ses métiers également. De ce fait, nous allons restreindre notre analyse au 5 principaux métiers, qui représentent à eux seuls près de 80% du panel professionnel interrogé.
Pour appuyer cette réflexion, nous nous sommes inspirés de cet article précisant qu'au sein même du métier de Data Scientist il y avait des différenciations:
https://www.journaldunet.com/solutions/dsi/1506951-de-l-avenir-du-metier-de-data-scientist-e/

## Filtre du data set sur les 5 principaux métiers
"""

#Liste Top 5 des professions du panel de répondant
top_5 =df['Q5'].value_counts().head().index.tolist()

top_5

#Création du df_top5
df_top5 = df[df['Q5'].isin (top_5)]

print('Notre dataset contient à présent', df_top5.shape[0], 'entrées et', df_top5.shape[1],'colonnes.')

"""Pour rappel, notre objectif est de créer un modèle capable de proposer un poste en fonction de compétences et d'outils associés. 
Par conséquent, en analysant les questions posées, nous pouvons supprimer une partie des colonnes.
"""

#Aperçu du data set
df.sample(2)

"""## Voici la liste des colonnes concernées et notre raisonnement:

## Colonnes à supprimer 
Q1 -> Age -> Dans un souci d'éthique, cette variable ne peut-être un élément différenciant pour une suggestion de poste

Q2 -> Genre-> Dans un souci d'éthique, cette variable ne peut-être un élément différenciant pour une suggestion de poste

Q3 -> Pays -> Dans un souci d'éthique, cette variable ne peut-être un élément différenciant pour une suggestion de poste

Q4 -> Niveau d'études-> Dans un souci d'éthique, cette variable ne peut-être un élément différenciant pour une suggestion de poste

Q8 -> Langage de programmation que la personne recommanderait -> Il s'agit d'une recommandation donc point de vue subjectif et non d'une compétence liée à un poste précis

Q11 -> Computing platform -> Il s'agit d'une habitude donc point de vue subjectif et non d'une compétence liée à un poste précis

Q12 -> Hardware / GPU ? TPU -> Il s'agit d'une habitude donc point de vue subjectif et non d'une compétence liée à un poste précis

Q13 -> Nb fois TPU used -> Il s'agit d'une habitude donc point de vue subjectif et non d'une compétence liée à un poste précis

Q18 -> Computer vision methods -> Question dépendant d'une réponse précédente et n'ayant pas été posée à tout le panel

Q19 -> NLP Methods -> Question dépendant d'une réponse précédente et n'ayant pas été posée à tout le panel

Q20 taille entreprise-> Question liée à l'entreprise et non au poste du répondant
Q21 combien de personnes en data
Q22 ML implémenté
Q24 salaire
Q25 combien d’argent dépensé

27A -> cloud computing products -> Question dépendant d'une réponse précédente et n'ayant pas été posée à tout le panel

28A -> ML products -> Question dépendant d'une réponse précédente et n'ayant pas été posée à tout le panel

Q30 -> Big Data products -> Question dépendant d'une réponse précédente et n'ayant pas été posée à tout le panel 

Q32 -> BI Tools -> Question dépendant d'une réponse précédente et n'ayant pas été posée à tout le panel 

Q34-A -> Automated ML Tools -> Question dépendant d'une réponse précédente et n'ayant pas été posée à tout le panel 

Q36 ->  Plateforme de publication -> Il ne s'agit pas d'une compétence technique ou d'un outil lié au poste

Q37 -> Plateforme de formation -> Il ne s'agit pas d'une compétence technique ou d'un outil lié au poste

Q38 -> Primary Tools for Data Analysis -> Il s'agit d'une réponse par texte libre

Q39 -> media favori -> Il ne s'agit pas d'une compétence technique ou d'un outil lié au poste

Q26_B à Q35_B -> Question dépendant d'une réponse précédente et n'ayant pas été posée à tout le panel

## Suppression des colonnes questions B
"""

#1) Sélection des questions avec 'B:'
quest_B =[]
for i in df_top5.columns.tolist():
  if 'B:' in i:
    quest_B.append(i)

print('Il y a',len(quest_B),'colonnes de questions partie B.')

quest_B

#2) Suppression des colonnes dans le DataFrame
df_top5 = df_top5.drop(quest_B, axis=1)

print('Notre dataset contient à présent', df_top5.shape[0], 'entrées et',df_top5.shape[1], 'colonnes.')
#Les 91 colonnes ont bien été supprimées.

"""##Suppression des autres colonnes

"""

#Recherche des colonnes avec + de 2 valeurs
#quest_u regroupe les colonnes des questions choix unique
#quest_u regroupe les colonnes des questions choix multiple
quest_u =[]
quest_m =[]
for i in df:
    if len(df[i].unique())>2:
        quest_u.append(i)
    else:
        quest_m.append(i)

#Création de la liste des colonnes à supprimer
col_to_drop =[]
for i in ['Q1', 'Q2', 'Q3', 'Q4', 'Q8',
          'Q11', 'Q12', 'Q13', 'Q18', 'Q19',
          'Q20', 'Q21', 'Q22', 'Q24', 'Q25', 'Q27A', 'Q28A',
          'Q34A', 'Q36', 'Q37', 'Q38', 'Q39']:
  if i not in col_to_drop:
    if i in quest_u:
      col_to_drop.append(i)
    else:
      for j in quest_m:
        if i in j:
          col_to_drop.append(j)

print('Nombre de colonnes à supprimer :', len(col_to_drop))
print(col_to_drop)

#Suppression de ces colonnes et création d'un nouveau df
df_clean = df_top5.drop(col_to_drop,axis=1)

print('Notre dataset contient à présent', df_clean.shape[0], 'entrées et',df_clean.shape[1], 'colonnes.')

df_clean.sample(2)

"""## Encodage des colonnes restantes:
L'ensemble des questions à choix multiple a déjà été traité précédemment.
Il nous reste à encoder Q6 et Q15.
"""

#Q6 Années d'expérience en programmation est une variable ordinale => encodage de 0 à 6
print(df_clean['Q6'].unique().tolist())

df_clean['Q6'] = df_clean['Q6'].replace(['I have never written code', '< 1 years', '1-2 years', '3-5 years', '5-10 years', '10-20 years', '20+ years'], [0,1,2,3,4,5,6])

#Vérif Q6
print(df_clean['Q6'].unique().tolist())

#Q15 Années d'expérience en programmation est une variable ordinale => encodage de 0 à 8
print(df_clean['Q15'].unique().tolist())

df_clean['Q15'] = df_clean['Q15'].replace(['I do not use machine learning methods','Under 1 year', '1-2 years','2-3 years','3-4 years','4-5 years','5-10 years','10-20 years','20 or more years'], [0,1,2,3,4,5,6,7,8])

#Vérif Q15
print(df_clean['Q15'].unique().tolist())

df_clean.sample(2)

#Retravail des intitulés de colonnes pour supprimer les espaces et caractères spéciaux
#df_clean = df_clean.rename(columns=lambda x: x.replace(' ', '_'))
#df_clean = df_clean.rename(columns=lambda x: x.replace(':', '_'))

"""# Itération 1: Choix du modèle d'apprentissage"""

#Création du vecteur 'target' contenant la variable cible 'Q5' et d'un Data Frame 'feats' contenant les différentes features.
target = df_clean['Q5']
feats=df_clean.drop('Q5', axis=1)

#Séparation du dataset en train set et test set
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(feats, target, test_size=0.2, random_state=200)

"""Notre variable cible étant une variable catégorielle composée de classes, nous utiliserons par la suite des modèles de classification. """

from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

from sklearn.preprocessing import StandardScaler
sc= StandardScaler()
X_train_scaled = sc.fit_transform(X_train)
X_test_scaled = sc.transform(X_test)

"""### Méthode Arbre de Décision"""

dtc = DecisionTreeClassifier()
dtc.fit(X_train_scaled, y_train)

dtc_y_pred = dtc.predict(X_test_scaled)

print('Score Train set du DecisionTree :',round(dtc.score(X_train_scaled, y_train),3)*100,'%')
print('Score Test set du DecisionTree :', round(dtc.score(X_test_scaled, y_test),5)*100,'%')

from sklearn.metrics import classification_report

print('Rapport de Classification Arbre de Décision')
print(classification_report(y_test, dtc_y_pred))

print("Matrice de confusion de l'Arbre de Décision")
pd.crosstab(y_test, dtc_y_pred, rownames=['Classe réelle'], colnames=['Classe prédite'])

"""### Méthide de Régression Logistique"""

lr = LogisticRegression()
lr.fit(X_train_scaled, y_train)

lr_y_pred = lr.predict(X_test_scaled)

print('Score Train set de la Regression Logistique',round(lr.score(X_train_scaled, y_train),4)*100,'%')
print('Score Test set de la Regression Logistique',round(lr.score(X_test_scaled, y_test),3)*100,'%')

print('Rapport de Classification Regression Logistique')
print(classification_report(y_test, lr_y_pred))

print("Matrice de confusion de la Regression Logistique")
pd.crosstab(y_test, lr_y_pred, rownames=['Classe réelle'], colnames=['Classe prédite'])

"""## Méthode des plus proches voisins (Minkowski, n=3)



"""

knn = KNeighborsClassifier(n_neighbors=3, metric='minkowski')
knn.fit(X_train_scaled, y_train)

knn_y_pred = knn.predict(X_test_scaled)

print('Score Train set de la méthode des k plus proches voisins',round(knn.score(X_train_scaled, y_train),4)*100,'%')
print('Score Test set de la méthode des k plus proches voisins',round(knn.score(X_test_scaled, y_test),3)*100,'%')

print('Rapport de Classification Méthode des k plus proches voisins')
print(classification_report(y_test, knn_y_pred))

print("Matrice de confusion des k plus proches voisins")
pd.crosstab(y_test, knn_y_pred, rownames=['Classe réelle'], colnames=['Classe prédite'])

"""## Méthode SVM - Support Vector Machine"""

from sklearn import model_selection
from sklearn import svm

svm = svm.SVC()
svm.fit(X_train_scaled, y_train)

svm_y_pred = svm.predict(X_test_scaled)

print('Score Train set du modèle SVM', round(svm.score(X_train_scaled, y_train), 4)*100, '%')
print('Score Test set du modèle SVM', round(svm.score(X_test_scaled, y_test), 4)*100, '%')

print('Rapport de Classification du modèle SVM')
print(classification_report(y_test, svm_y_pred))

print("Matrice de confusion du modèle SVM")
pd.crosstab (y_test, svm_y_pred, rownames= ['Classe réelle'], colnames = ['Classe prédite'])

"""## Méthode - Random Forest"""

rf = RandomForestClassifier ()
rf.fit(X_train_scaled, y_train)

rf_y_pred = rf.predict(X_test_scaled)

print('Score Train set du modèle Random Forest', round(rf.score(X_train_scaled, y_train), 4)*100, '%')
print('Score Test set du modèle Random Forest', round(rf.score(X_test_scaled, y_test), 4)*100, '%')

print('Rapport de Classification du modèle Random Forest')
print(classification_report(y_test, rf_y_pred))

print("Matrice de confusion du modèle Random Forest")
pd.crosstab (y_test, rf_y_pred, rownames= ['Classe réelle'], colnames = ['Classe prédite'])

"""## Comparaison des scores de chaque modèle entraîné"""

Data = {'Method' : ['dtc','lr','knn','svm','rf'],
        'Method_Name' : ['DecisionTreeClassifier','LogisticRegression','KNeighborsClassifier','svm.SVC','RandomForestClassifier'],
        'Score_Train' : [0.975, 0.5825, 0.6313, 0.7425, 0.9751],
        'Score_Test' : [0.4036, 0.5430, 0.3820, 0.5433, 0.5337],
        'precision(macro_avg)' : [0.37, 0.51, 0.40, 0.54, 0.52],
        'recall(macro_avg)' : [0.37, 0.49, 0.35, 0.48, 0.46],
        'f1_score(macro_avg)' : [0.37, 0.50, 0.35, 0.49, 0.47],
        'precision(weighted_avg)' : [0.41, 0.53, 0.42, 0.54, 0.53],
        'recall(weighted_avg)' : [0.40, 0.54, 0.38, 0.54, 0.53],
        'f1_score(weighted_avg)' : [0.40, 0.53, 0.38, 0.53, 0.52]}

Scores = pd.DataFrame(Data)

Scores.head()

plt.figure(figsize=(10,15))

plt.subplot(3,1,1)

plt.plot(Scores['Method'],Scores['Score_Train'],color='red',marker='D',linewidth=2,label='Train')
plt.plot(Scores['Method'],Scores['Score_Test'],color='blue',marker='D',linewidth=2,label='Test')
plt.xlabel('Méthode')
plt.ylabel('Scores')
plt.ylim([0.3,1])
plt.title('\nComparaison des différentes méthodes de classification\n\n',fontsize=20)
plt.legend(loc='upper center')

plt.subplot(3,1,2)
plt.plot(Scores['Method'],Scores['precision(macro_avg)'],color='green',linewidth=1,label='Precision')
plt.plot(Scores['Method'],Scores['recall(macro_avg)'],color='orange',linewidth=1,label='Recall')
plt.plot(Scores['Method'],Scores['f1_score(macro_avg)'],color='gray',linewidth=1,label='F1-score')
plt.xlabel('Méthode\n')
plt.ylabel('Scores (macro avg)')
plt.legend(loc='upper center')

plt.subplot(3,1,3)
plt.plot(Scores['Method'],Scores['precision(weighted_avg)'],color='green',linewidth=1,label='Precision')
plt.plot(Scores['Method'],Scores['recall(weighted_avg)'],color='orange',linewidth=1,label='Recall')
plt.plot(Scores['Method'],Scores['f1_score(weighted_avg)'],color='gray',linewidth=1,label='F1-score')
plt.xlabel('Méthode')
plt.ylabel('Scores (weighted_avg)')
plt.legend(loc='upper center')

plt.show()

df_clean.to_csv('/content/drive/MyDrive/Data/df_clean.csv')